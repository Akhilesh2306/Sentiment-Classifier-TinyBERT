{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4934358d",
   "metadata": {},
   "source": [
    "## **`Sentiment Classification using TinyBERT`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c7793",
   "metadata": {},
   "source": [
    "#### BERT (Bidirectional Encoder Representations from Transformers)\n",
    "\n",
    "Developed by Google in 2018.\n",
    "A large transformer-based language model.\n",
    "Pretrained on massive text corpora (BooksCorpus + Wikipedia) using masked language modeling and next sentence prediction.\n",
    "Captures bidirectional context (left + right) in sentences.\n",
    "Very powerful but computationally heavy (large number of parameters).\n",
    "\n",
    "#### TinyBERT\n",
    "\n",
    "A smaller, faster, and lighter version of BERT, created through knowledge distillation.\n",
    "The large BERT (teacher model) transfers its knowledge to a smaller student model.\n",
    "Maintains most of BERTâ€™s accuracy while being much more efficient for real-time and edge applications (e.g., mobile devices).\n",
    "Useful for tasks like text classification, sentiment analysis, and question answering where low latency is needed.\n",
    "\n",
    "ðŸ‘‰ In short: BERT = big, accurate, resource-heavy.\n",
    "TinyBERT = compact, efficient, still good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf8134",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305a395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import torch\n",
    "import posixpath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03141737",
   "metadata": {},
   "source": [
    "### **Load Data using HuggingFace Datasets library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae128fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://github.com/laxmimerit/All-CSV-ML-Data-Files-Download/raw/refs/heads/master/IMDB-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06199b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001cc052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7582ac8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review', 'sentiment'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Converting to Huggingface Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3aabda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 35000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Splitting data into train and test\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ca5f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28df5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"negative\": 0, \"positive\": 1}\n",
    "id2label = {0: \"negative\", 1: \"positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667cf019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15cb07471304b22927bc22158185474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add0bc27783348a2a50e4adabd3bbf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment', 'label'],\n",
       "        num_rows: 35000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review', 'sentiment', 'label'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: {\"label\": label2id[x[\"sentiment\"]]})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a456079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'A phenomenal achievement in awfulness. It\\'s actually hilariously awful.<br /><br />First off...Nicholas Cage must now have made it to the finals in the Over-Emoting Category in his acting class. Wearing new hair plugs and with a face that has been lifted so many times his pinned back ears seem to be straining to touch in the back he oozes not only a sick smarmiess but creates a \"hero\" character that you have no vested interest in.<br /><br />I don\\'t know what it is with Neil Labute and female characters. He makes females out to be totally deviant and evil...and pays them back by having Cage punch several of them directly in the face and call them all \"b****es\" a few times too. I\\'ve enjoyed LaBute\\'s early films and a few of his plays...but it\\'s a strange fascination he has.<br /><br />I\\'d give this film a 2 out of 10 solely based on Ellen Burstyn\\'s performance. By the time she finally makes her appearance (bravely soldiering through her scenes with her wig line clearly visible on her forehead) it seems like all hope may be lost. She deserves an Oscar right here and now for saying her lines with a straight face and when she appears wearing a white mumu and blue, white, and gold face paint booming about The Wicker Man you know that working with Scorcese and Friedkin really prepped her for this role dang well.<br /><br />This movie is so wrong-headed and cuckoo that is has to be seen to be believed.<br /><br />Highlights include: Nicholas Cage running away from a swarm of bees and then falling down a hill.<br /><br />Nicholas Cage stealing a bicycle and looking like Ms. Gulch from The Wizard of Oz riding around on it.<br /><br />Nicholas Cage running around the island kicking down doors looking for the missing girl.<br /><br />Leelee Sobieski PLUMMETING from a once-promising acting career in a \"brawl\" with Cage.<br /><br />Ellen Burstyn dancing around in a said while mumu.<br /><br />Nicholas Cage screaming \"Who burned it? Who burned it? Who burned it?Who burned it?Who burned it?Who burned it?\" for no reason.<br /><br />Nicholas Cage in a bear costume (I\\'m not kidding) running through the woods, taking off the costume (but leaving the bear feet on) and then doing some karate moves to some villains.<br /><br />And you haven\\'t lived until you have seen the final 15 minutes of the movie and its dreadful epilogue that looked like it was shot yesterday in your cousin\\'s basement.<br /><br />Needless to say, if you can make it through this film without laughing out loud then you deserve a medal. There was actually a point in the movie where I stopped snickering to wonder if maybe this wasn\\'t an elaborate send-up of \"hysteria\" films...only to be reminded when Cage would scream/shout/whisper his dialogue that he really was taking himself quite seriously.<br /><br />I think this one is destined to be a cult film all over again...just because it\\'s so dreadful.',\n",
       " 'sentiment': 'negative',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea033f",
   "metadata": {},
   "source": [
    "### **Data Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdd3f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"huawei-noah/TinyBERT_General_4L_312D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6862937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5b9bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='huawei-noah/TinyBERT_General_4L_312D', vocab_size=30522, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df8f844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2001, 3201, 2005, 1037, 21676, 2075, 6816, 2806, 3185, 1998, 2035, 1045, 2288, 2001, 1996, 5409, 3185, 1045, 1005, 2310, 2464, 1999, 2086, 1012, 2009, 2001, 2471, 2004, 2919, 2004, 5797, 3854, 14163, 12680, 14691, 5054, 1012, 2757, 5896, 1012, 2757, 3772, 1012, 2757, 2673, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 4379, 2045, 2001, 2070, 2204, 2954, 5019, 2021, 1996, 3893, 2217, 4515, 2045, 1012, 2065, 2023, 3185, 8480, 1999, 2115, 2160, 2448, 8040, 28578, 2075, 2000, 1037, 3042, 1998, 13764, 19989, 1998, 2360, 1010, 1000, 3531, 2393, 2045, 2003, 1037, 3185, 1999, 2026, 2160, 3214, 2000, 2486, 2111, 2000, 10797, 5920, 1000, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset[\"train\"][1][\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa69c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    temp = tokenizer(batch[\"review\"], padding=True, truncation=True, max_length=300)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d529e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e513135b79f40659de51c66aaa706d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4b6b37e1734858b31818567dbe33c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897bda5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['review', 'sentiment', 'label', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c8fb7",
   "metadata": {},
   "source": [
    "### **Building Model Evaluation**\n",
    "\n",
    "- https://huggingface.co/docs/transformers/v4.42.0/en/tasks/sequence_classification#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ef91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8de6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c67f90",
   "metadata": {},
   "source": [
    "### **Building Model Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae972eae",
   "metadata": {},
   "source": [
    "- `AutoModelForSequenceClassification` model has a classification head on top of the pretrained model outputs\n",
    "- The first thing we need is a pretrained BERT-like model.\n",
    "- The only slight modification is that we use the `AutoModelForSequenceClassification` model instead of AutoModel.\n",
    "- The difference is that the `AutoModelForSequenceClassification` model has a classification head on top of the pretrained model outputs, which can be easily trained with the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8d6cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec8ca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "347d2433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2c2e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = \"sentiment-train_dir\",\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs = 3,\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"test\"],\n",
    "    compute_metrics = compute_metrics,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ddbc11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3282' max='3282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3282/3282 12:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.309081</td>\n",
       "      <td>0.867933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.288847</td>\n",
       "      <td>0.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.292007</td>\n",
       "      <td>0.880400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3282, training_loss=0.31753584439256144, metrics={'train_runtime': 746.0679, 'train_samples_per_second': 140.738, 'train_steps_per_second': 4.399, 'total_flos': 882184338000000.0, 'train_loss': 0.31753584439256144, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2b7fb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhileshdeshmukh/Study/virtual-environs/ml_deploy_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='469' max='469' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [469/469 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2920065224170685,\n",
       " 'eval_accuracy': 0.8804,\n",
       " 'eval_runtime': 23.8391,\n",
       " 'eval_samples_per_second': 629.22,\n",
       " 'eval_steps_per_second': 19.674,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b147946",
   "metadata": {},
   "source": [
    "### **Save model and Load for Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31ec164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"sentiment-classifier-tinyBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898d6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = [\n",
    "    \"Absolutely loved this movie! The story was engaging and the performances were top-notch.\",\n",
    "    \"A delightful film with great acting and a heartwarming message. Highly recommended!\",\n",
    "    \"This was a complete waste of time. The plot was predictable and the acting was terrible.\",\n",
    "    \"I didn't enjoy this movie at all. The pacing was slow and the characters were uninteresting.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1617d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9879263639450073},\n",
       " {'label': 'positive', 'score': 0.9894049167633057},\n",
       " {'label': 'negative', 'score': 0.9905412793159485},\n",
       " {'label': 'negative', 'score': 0.9911723732948303}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(task=\"text-classification\", model=\"sentiment-classifier-tinyBERT\", device=device)\n",
    "\n",
    "sentiment_classifier(sample_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0a55c",
   "metadata": {},
   "source": [
    "### **Push Trained Sentiment Classifier model to AWS S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e969f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "bucket_name = \"bert-based-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a079ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name):\n",
    "    s3_buckets = [bucket[\"Name\"] for bucket in s3_client.list_buckets()[\"Buckets\"]]\n",
    "\n",
    "    if bucket_name not in s3_buckets:\n",
    "        s3_client.create_bucket(\n",
    "            Bucket=bucket_name, \n",
    "            CreateBucketConfiguration={\"LocationConstraint\": \"ap-south-1\"}\n",
    "        )\n",
    "        return(f\"Bucket {bucket_name} created successfully\")\n",
    "\n",
    "    return(\"Bucket already exists in your account!!! Feel free to use it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ccbba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bucket already exists in your account!!! Feel free to use it.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b23c24cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'Q7JBAAK0S1V5SGMR',\n",
       "  'HostId': 'FDkvq+OVf1McnNu73TzvI86v3zMEPuswsnVO6q3ttXTbtWiCTr1lCs6Nwag4k34usdpiw64uUA0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'FDkvq+OVf1McnNu73TzvI86v3zMEPuswsnVO6q3ttXTbtWiCTr1lCs6Nwag4k34usdpiw64uUA0=',\n",
       "   'x-amz-request-id': 'Q7JBAAK0S1V5SGMR',\n",
       "   'date': 'Mon, 18 Aug 2025 22:46:16 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'bert-based-project',\n",
       "   'CreationDate': datetime.datetime(2025, 8, 18, 20, 47, 29, tzinfo=tzutc())}],\n",
       " 'Owner': {'ID': '9594599b0b363b01690f507e083d2f2038c964873451ac0a90d0ce794286321a'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_client.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "644cf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Upload model folder to S3 bucket bert-based-project in ml-models/sentiment-classifier-tinyBERT\n",
    "\n",
    "def upload_directory(bucket_name, dir_path, s3_prefix):\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            # Full local path\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            # Relative path (keeps folder structure in S3)\n",
    "            rel_path = os.path.relpath(file_path, dir_path)\n",
    "\n",
    "            # S3 key (use posixpath to enforce \"/\")\n",
    "            s3_key = posixpath.join(s3_prefix, rel_path)\n",
    "            \n",
    "            print(f\"Uploading {file_path} â†’ s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "            s3_client.upload_file(file_path, bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83ddedaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading sentiment-classifier-tinyBERT/model.safetensors â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/model.safetensors\n",
      "Uploading sentiment-classifier-tinyBERT/tokenizer_config.json â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/tokenizer_config.json\n",
      "Uploading sentiment-classifier-tinyBERT/special_tokens_map.json â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/special_tokens_map.json\n",
      "Uploading sentiment-classifier-tinyBERT/config.json â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/config.json\n",
      "Uploading sentiment-classifier-tinyBERT/tokenizer.json â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/tokenizer.json\n",
      "Uploading sentiment-classifier-tinyBERT/training_args.bin â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/training_args.bin\n",
      "Uploading sentiment-classifier-tinyBERT/vocab.txt â†’ s3://bert-based-project/ml-models/sentiment-classifier-tinyBERT/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "upload_directory(bucket_name, \"sentiment-classifier-tinyBERT\", \"ml-models/sentiment-classifier-tinyBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5657b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-venv",
   "language": "python",
   "name": "ml_deploy_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
